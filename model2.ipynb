{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1 & 2:\n",
    "### 경형·소형 트럭: 경형 1톤 이하, 소형 2톤 미만 차급\n",
    "\n",
    "- __Model1__: 카고형\n",
    "- __Model2__: 박스형(윙바디/탑, 냉동, 냉장)\n",
    "- __archive__: 포터 봉고 순정특장차(홈로리, 활어차, 덤프)\n",
    "- 1톤 Base ( t >= 0.5 & t < 2)\n",
    "- 소형트럭은 적재중량 1톤 이상 2톤 미만 차급을 지칭한다.<br>\n",
    "  연간 신규등록대수는 약 15만대로, 트럭 시장에서 가장 많은 등록대수를 차지한다.\n",
    "  용도 또한 용달, 개별 등을 비롯해, 농어촌 자가용 역할 등 많은 역할을 수행한다.\n",
    "  대표모델로는 현대차 포터와 기아차 봉고가 있으며, 이외 최근 몇몇 업체서 소형급 전기트럭을 준비하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp as hps, tpe\n",
    "import pickle\n",
    "# modules 폴더를 path에 추가(본인 컴퓨터에 맞게 수정)\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "module_path = root_path + '\\\\modules'\n",
    "sys.path.insert(1, module_path)\n",
    "from common import common as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import json\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "font_path = \"../../../assets/fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "# 하나의 cell에서 multiple output 출력\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# float > 소수점 두자리까지만\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "# 컬럼 길이 제한 없음\n",
    "try:\n",
    "    pd.set_option('max_columns', None)\n",
    "    pd.set_option('max_rows', 500)\n",
    "except:\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = 500\n",
    "\n",
    "# 아래 코드에서 100%를 본인이 원하는 비율로 조정하여, 가로로 넓게 코드작성이 가능하고, 데이터를 보는데 쾌적한 환경을 조성할 수 있음\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call 아이트럭 raw data\n",
    "from calldb import db_helper\n",
    "itruck = db_helper(server=\"REL\").table(\"SELECT * FROM TB_MYCAR;\")\n",
    "\n",
    "max_workers = min(32, os.cpu_count() + 4)\n",
    "# call 특장차8949 raw data\n",
    "tjc = cm.read_all_csv(path=root_path+\"/assets/csv/특장차8949/\", workers=max_workers)\n",
    "\n",
    "# call 카매니저 raw data\n",
    "cmg = cm.read_all_json(path=root_path+\"/assets/json/카매니저/metaData/\", workers=max_workers)\n",
    "\n",
    "print(f\"itruck shape: {itruck.shape}\\ntjc shape: {tjc.shape}\\ncmg shape: {cmg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df):\n",
    "    df = df.drop(columns=['id'])\n",
    "    \n",
    "    df = df[df['f_brand'].isin(['현대', '기아'])]\n",
    "    df.loc[df['f_brand'] == '기아', 'f_brand'] = 0\n",
    "    df.loc[df['f_brand'] == '현대', 'f_brand'] = 1\n",
    "    df['f_year'] = pd.to_datetime(df['f_year'])\n",
    "    df['f_reg_dt'] = pd.to_datetime(df['f_reg_dt'])\n",
    "    df['f_category'] = df['f_category'].replace({\n",
    "        '내장탑': 'top',\n",
    "        '냉동냉장차': 'refrige',\n",
    "        '윙바디': 'wing',\n",
    "    })\n",
    "    \n",
    "    df.loc[df['f_trm'] == '수동', 'f_trm'] = 0\n",
    "    df.loc[df['f_trm'] == '오토', 'f_trm'] = 1\n",
    "    df.loc[df['f_elec_yn'] == False, 'f_elec_yn'] = 0\n",
    "    df.loc[df['f_elec_yn'] == True, 'f_elec_yn'] = 1\n",
    "    df = pd.get_dummies(df, columns=[\"f_category\"])\n",
    "    \n",
    "    y = df.pop('l_price')\n",
    "    X = df\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    for col in X:\n",
    "        X[col] = scaler.fit_transform(X[[col]])\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "# ../../../assets/csv/시세예측/raw/model2/ 경로에서 가장 최근의 파일을 불러옴\n",
    "df = pd.read_csv(sorted(glob.glob(\"../../../assets/csv/시세예측/raw/model2/*.csv\"))[-1], encoding='cp949')\n",
    "scaled_df = df.copy()\n",
    "X, y = scale(scaled_df)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization candiate 정의\n",
    "reg_candidate = [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "# space 정의, Hyperparameter의 이름을 key 값으로 입력(xgboost)\n",
    "space={\n",
    "    'max_depth': hps.quniform(\"max_depth\", 5, 20, 1), # 트리의 최대 깊이\n",
    "    'learning_rate': hps.quniform ('learning_rate', 0.01, 0.05, 0.005), # 학습률\n",
    "    'reg_alpha': hps.choice('reg_alpha', reg_candidate), # L1정규화 Lasso회귀분석\n",
    "    'reg_lambda': hps.choice('reg_lambda', reg_candidate), # L2정규화 Ridge회귀분석\n",
    "    'subsample': hps.quniform('subsample', 0.01, 1, 0.01), # 트리를 생성할 때 데이터를 샘플링하는 비율\n",
    "    'colsample_bytree': hps.quniform('colsample_bytree', 0.01, 1, 0.01), # 트리를 생성할 때 피처를 샘플링하는 비율\n",
    "    'colsample_bylevel': hps.quniform('colsample_bylevel', 0.01, 1, 0.01), # 트리의 레벨별로 피처를 샘플링하는 비율\n",
    "    'colsample_bynode': hps.quniform('colsample_bynode', 0.01, 1, 0.01), # 트리의 노드별로 피처를 샘플링하는 비율\n",
    "    'min_child_weight': hps.quniform('min_child_weight', 1, 100, 1), # 트리의 리프노드가 되기 위한 최소한의 샘플 데이터 수\n",
    "    'n_estimators': hps.quniform('n_estimators', 100, 10000, 100), # 트리의 개수\n",
    "    'gamma': hps.quniform('gamma', 0.01, 1, 0.01), # 트리의 리프노드를 추가적으로 나눌지를 결정하는 파라미터\n",
    "}\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators =int(space['n_estimators']), \n",
    "        max_depth = int(space['max_depth']), \n",
    "        learning_rate = space['learning_rate'],\n",
    "        reg_alpha = space['reg_alpha'], # L1정규화 Lasso회귀분석\n",
    "        reg_lambda = space['reg_lambda'], # L2정규화 Ridge회귀분석\n",
    "        subsample = space['subsample'], # 각 트리마다의 관측 데이터 샘플링 비율\n",
    "        colsample_bytree = space['colsample_bytree'], # 각 트리마다의 feature 샘플링 비율\n",
    "        colsample_bylevel = space['colsample_bylevel'], # 각 트리 depth 마다 사용할 feature 비율\n",
    "        colsample_bynode = space['colsample_bynode'], # 각 트리 node 마다 사용할 feature 비율\n",
    "        min_child_weight = int(space['min_child_weight']), # child의 관측에서 요구되는 최소 가중치의 합(overfitting 조정 parameter)\n",
    "        gamma = space['gamma'], # 트리의 리프노드를 추가적으로 나눌지를 결정하는 파라미터\n",
    "        random_state=200, \n",
    "    )\n",
    "    \n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=evaluation, \n",
    "        eval_metric=\"rmse\",\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=0,\n",
    "    )\n",
    "    pred = model.predict(X_test)\n",
    "    rmse= cm.RMSE(y_test, pred)\n",
    "    # 평가 방식 선정\n",
    "    \n",
    "    return {'loss':rmse, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials 객체 선언합니다.\n",
    "trials = Trials()\n",
    "\n",
    "# best에 최적의 하이퍼 파라미터를 return 받습니다.\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials\n",
    "        )\n",
    "\n",
    "# 최적화된 결과를 int로 변환해야하는 파라미터는 타입 변환을 수행합니다.\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_weight'] = int(best['min_child_weight'])\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['reg_alpha'] = reg_candidate[int(best['reg_alpha'])]\n",
    "best['reg_lambda'] = reg_candidate[int(best['reg_lambda'])]\n",
    "best['random_state'] = 200\n",
    "print(best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation, Get Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "def kfold_xgb(xgb: XGBRegressor, X, y, n_splits=5, random_state=100):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    result = []\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        d = {}\n",
    "        loss = {\n",
    "            'MAE': \"\",\n",
    "            'RMSE': \"\",\n",
    "            'RMSLE': \"\",\n",
    "            'MAPE': \"\",\n",
    "            'R2': \"\",\n",
    "        }\n",
    "        print(f'Fold {i+1}: ')\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        now = time.time()\n",
    "        xgb.fit(X_train, y_train)\n",
    "        print(f'학습 시간: {time.time()-now:.2f}초')\n",
    "        now = time.time()\n",
    "        pred = xgb.predict(X_test)\n",
    "        TT_Sec = time.time()-now\n",
    "        print(f'예측 시간: {TT_Sec:.2f}초')\n",
    "        print('--------------------------------------')\n",
    "        loss['MAE'], loss['RMSE'], loss['RMSLE'], loss['MAPE'], loss['R2'], loss['TT(Sec)'] = cm.MAE(y_test, pred), cm.RMSE(y_test, pred), cm.RMSLE(y_test, pred), cm.MAPE(y_test, pred), cm.R2(y_test, pred), TT_Sec\n",
    "        result.append({\"model\": xgb, \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test, \"pred\": pred, \"loss\": loss})\n",
    "        \n",
    "    return result\n",
    "\n",
    "xgb = XGBRegressor(**best)\n",
    "result = kfold_xgb(xgb, X, y, n_splits=10, random_state=200)\n",
    "best_result = result[np.argmin([r['loss']['RMSLE'] for r in result])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([r['loss'] for r in result], index=[f'Fold {i+1}' for i in range(len(result))])\n",
    "\n",
    "print(f'Best: Fold {np.argmin([r[\"loss\"][\"RMSLE\"] for r in result])+1}')\n",
    "pred_df = pd.DataFrame({\n",
    "    '실제값': best_result['y_test'],\n",
    "    '예측값': best_result['pred'],\n",
    "})\n",
    "pred_df['오차값'] = (pred_df['예측값'] - pred_df['실제값'])\n",
    "pred_df['절대 오차값'] = (pred_df['예측값'] - pred_df['실제값']).abs()\n",
    "pred_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def show_plot():\n",
    "    dfs = {f\"Fold {i+1}\": pd.DataFrame({\n",
    "        '실제값': r['y_test'],\n",
    "        '예측값': r['pred'],\n",
    "        '오차값': (r['pred'] - r['y_test']),\n",
    "    }) for i, r in enumerate(result)}\n",
    "\n",
    "    y_len = len(result)\n",
    "    figure, axis = plt.subplots(y_len, 2, figsize=(20, 10*y_len))\n",
    "\n",
    "    best_fold = f'Fold {np.argmin([r[\"loss\"][\"RMSLE\"] for r in result])+1}'\n",
    "    for i, (key, df) in enumerate(dfs.items()):\n",
    "        # grid true\n",
    "        axis[i][0].grid(True)\n",
    "        x_line = np.arange(0, df[['실제값', '예측값']].max().max())\n",
    "        y_line = x_line + 0\n",
    "        axis[i][0].axis([df['실제값'].min(), df['실제값'].max(), df['예측값'].min(), df['예측값'].max()])\n",
    "        axis[i][0].scatter(df['실제값'], df['예측값'], alpha=.5, s=10)\n",
    "        axis[i][0].plot(x_line, y_line, color='red')  # draw line\n",
    "        axis[i][0].set_xlabel(df['실제값'].name)\n",
    "        axis[i][0].set_ylabel(df['예측값'].name)\n",
    "        if key == best_fold:\n",
    "            axis[i][0].set_title(key + ' (Best)')\n",
    "        else:\n",
    "            axis[i][0].set_title(key)\n",
    "        \n",
    "        # grid true\n",
    "        axis[i][1].grid(True)\n",
    "        axis[i][1].axis([df['실제값'].min(), df['실제값'].max(), df['오차값'].min(), df['오차값'].max()])\n",
    "        axis[i][1].scatter(df['실제값'], df['오차값'], alpha=.5, s=10)\n",
    "        axis[i][1].plot([df['실제값'].min(), df['실제값'].max()], [0, 0], color='red')\n",
    "        axis[i][1].set_xlabel(df['실제값'].name)\n",
    "        axis[i][1].set_ylabel(df['오차값'].name)\n",
    "        if key == best_fold:\n",
    "            axis[i][1].set_title(key + ' (Best)')\n",
    "        else:\n",
    "            axis[i][1].set_title(key)\n",
    "        # linear regression for 오차값\n",
    "        x_r = df['실제값'].values.reshape(-1, 1)\n",
    "        y_r = df['오차값'].values.reshape(-1, 1)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x_r, y_r)\n",
    "        axis[i][1].plot(x_r, lr.predict(x_r), color='green')\n",
    "        \n",
    "    plt.show();\n",
    "    \n",
    "show_plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dt = datetime.now()\n",
    "\n",
    "model_path = \"../../../assets/csv/시세예측/model/model2\"\n",
    "train_path = \"../../../assets/csv/시세예측/train/model2\"\n",
    "test_path = \"../../../assets/csv/시세예측/test/model2\"\n",
    "cm.create_folder(model_path)\n",
    "cm.create_folder(train_path)\n",
    "cm.create_folder(test_path)\n",
    "\n",
    "# save xgBoost Model\n",
    "best_result['model'].save_model(f\"{model_path}/xg.{save_dt.strftime('%Y%m%d%H%I%S')}.json\")\n",
    "best_result['model'].save_model(f\"{model_path}/xg.{save_dt.strftime('%Y%m%d%H%I%S')}.model\")\n",
    "\n",
    "# save minMaxScaler Model\n",
    "mm_model = df.loc[best_result['X_train'].index][['f_mileage', 'f_year']].reset_index(drop=True)\n",
    "transformed_datetime = cm.transform_date(mm_model['f_year'].values.reshape(-1, 1))\n",
    "mm_model = pd.concat([mm_model, pd.DataFrame(transformed_datetime, columns=['transformed_datetime'])], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "mm_fit = scaler.fit(mm_model.drop(columns=['f_year']))\n",
    "\n",
    "with open(f\"{model_path}/mm.{save_dt.strftime('%Y%m%d%H%I%S')}.model\", 'wb') as f:\n",
    "    pickle.dump(mm_fit, f)\n",
    "    \n",
    "# save test, train set\n",
    "best_result['X_train'].to_csv(f\"{train_path}/X_train.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['X_test'].to_csv(f\"{test_path}/X_test.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['y_train'].to_csv(f\"{train_path}/y_train.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['y_test'].to_csv(f\"{test_path}/y_test.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4072f32cd894d8a478b19fcca03df2d0ab244b2d541bc7c55c292e4acce29c8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
