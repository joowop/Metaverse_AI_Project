{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: 트랙터\n",
    "\n",
    "### Features: \n",
    "- 주행거리, 연식, 모델, 캡(0: 표준, 1: 하이), 제조사(볼보, 현대, 스카니아, 벤츠, 만, 타타대우, 이베코), 등록일(매물 업로드일), 변속기, 마력, 축(4x2, 6x2, 6x4)\n",
    "\n",
    "트랙터와 트레일러는 커플러(Coupler)와 킹핀(King Pin)으로 연결된다. <br>\n",
    "트랙터에 장착되어 있는 것이 커플러, 트레일러에 장착되어 있는 것이 킹핀이다. <br>\n",
    "커플러는 Fifth Wheel Coupler 즉, 5륜 연결기가 그 원명이다. 자동차의 4륜외에 또 하나의<br>\n",
    "하중 분담과 조향의 역할을 하는 다섯 번째 휠을 둔다는 의미에서 비롯된 말로 세계 공통어로 사용되고 있다.<br>\n",
    "커플러는 트레일러의 킹핀과 연결되어 하중지지 및 회전을 용이하도록 해 준다. <br>\n",
    "커플러 내부에는 죠(Jaw)가 장착되어 있어 차체의 충격, 진동 등이 커플러에 전달되어도 킹핀이 빠져나가지 못하도록 되어 있다.\n",
    "\n",
    "참고자료:\n",
    "    벤츠: https://www.mercedes-benz-trucks.com/content/dam/mbo/markets/ko_KR/brand/catalogue/2022/221004_actros_L.pdf <br>\n",
    "    스카니아: https://www.scania.com/content/dam/www/market/kr/truck/catalogue/%ED%8A%B8%EB%9E%99%ED%84%B0_%EC%B9%B4%ED%83%88%EB%A1%9C%EA%B7%B8_2022.pdf <br>\n",
    "    볼보: https://www.volvotrucks.kr/content/dam/volvo-trucks/markets/korea/brochure/44p%20TRACTOR_20220502.pdf <br>\n",
    "    민: https://mantruck.co.kr/catalog/\n",
    "\n",
    "    '''\n",
    "    __트랙터 라벨링 documents__\n",
    "    \n",
    "    캡: \n",
    "        하이탑, 하이, 글로벌, 글로브 등과 같은 단어가 모델 또는 상세설명 컬럼에 붙어있으면 하이탑, 이외는 표준탑(일반탑)\n",
    "    \n",
    "    축: \n",
    "        원데후, 원대후, 완데후 등과 같은 단어가 포함되면서 총 바퀴 수가 6개면 6x2 // 총 바퀴수가 4개면 4x2 // 투데후, 투대후 등과 같은 단어가 포함되면서 총 바퀴수가 6개면 6x4\n",
    "       \n",
    "    마력: \n",
    "        3자리 숫자가 연속되면 마력으로 의심. 대개 300이상 800이하의 숫자임\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp as hps, tpe\n",
    "import pickle\n",
    "# modules 폴더를 path에 추가(본인 컴퓨터에 맞게 수정)\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "module_path = root_path + '\\\\modules'\n",
    "sys.path.insert(1, module_path)\n",
    "from common import common as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import json\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "font_path = \"../../../assets/fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "# 하나의 cell에서 multiple output 출력\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# float > 소수점 두자리까지만\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "# 컬럼 길이 제한 없음\n",
    "try:\n",
    "    pd.set_option('max_columns', None)\n",
    "    pd.set_option('max_rows', 500)\n",
    "except:\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = 500\n",
    "\n",
    "# 아래 코드에서 100%를 본인이 원하는 비율로 조정하여, 가로로 넓게 코드작성이 가능하고, 데이터를 보는데 쾌적한 환경을 조성할 수 있음\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call 아이트럭 raw data\n",
    "from calldb import db_helper\n",
    "itruck = db_helper(server=\"REL\").table(\"SELECT * FROM TB_MYCAR;\")\n",
    "\n",
    "max_workers = min(32, os.cpu_count() + 4)\n",
    "# call 특장차8949 raw data\n",
    "tjc = cm.read_all_csv(path=root_path+\"/assets/csv/특장차8949/\", workers=max_workers)\n",
    "\n",
    "# call 카매니저 raw data\n",
    "cmg = cm.read_all_json(path=root_path+\"/assets/json/카매니저/metaData/\", workers=max_workers)\n",
    "\n",
    "print(f\"itruck shape: {itruck.shape}\\ntjc shape: {tjc.shape}\\ncmg shape: {cmg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df):\n",
    "    modelConverter = {\n",
    "        '현대': [\n",
    "            ['파워트럭', '트라고'],\n",
    "            ['엑시언트'],\n",
    "        ],\n",
    "        # 타타대우: 노부스 < 프리마 = 맥쎈\n",
    "        '타타대우': [\n",
    "            ['노부스'], \n",
    "            ['프리마', '맥쎈'],\n",
    "        ],\n",
    "        # 볼보: FL < FM < FH\n",
    "        '볼보': [\n",
    "            ['FL'], \n",
    "            ['FM'], \n",
    "            ['FH'],\n",
    "        ],\n",
    "        # 스카니아: L < P < G < R < S\n",
    "        '스카니아': [\n",
    "            ['L'],\n",
    "            ['P'],\n",
    "            ['G'],\n",
    "            ['R'],\n",
    "            ['S'],\n",
    "        ],\n",
    "        '만': [\n",
    "            ['TGA', 'TGX'],\n",
    "        ],\n",
    "        '벤츠': [\n",
    "            ['악트로스'],\n",
    "        ],\n",
    "        '이베코': [\n",
    "            ['스트라리스'],\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    axleConverter = {\n",
    "        '6x2': 0,\n",
    "        '6x4': 1,\n",
    "    }\n",
    "\n",
    "    cabConverter = {\n",
    "        '표준탑': 0,\n",
    "        '중간탑': 1,\n",
    "        '하이탑': 2,\n",
    "        '글로벌': 2,\n",
    "    }\n",
    "\n",
    "    brandConverter = {\n",
    "        '현대': 'hyundai',\n",
    "        '볼보': 'volvo',\n",
    "        '스카니아': 'scania',\n",
    "        '만': 'man',\n",
    "        '타타대우': 'daewoo',\n",
    "        '벤츠': 'benz',\n",
    "        '이베코': 'iveco',\n",
    "    }\n",
    "    df = df.drop(columns=['id'])\n",
    "    \n",
    "    for k1, v1 in modelConverter.items():\n",
    "        for i, v2 in enumerate(v1):\n",
    "            df.loc[(df['f_brand'] == k1) & (df['f_model'].isin(v2)), 'f_model'] = i\n",
    "            \n",
    "    df['f_axle'] = df['f_axle'].fillna(0).replace(axleConverter)\n",
    "    df['f_cab'] = df['f_cab'].fillna(0).replace(cabConverter)\n",
    "    df['f_brand'] = df['f_brand'].replace(brandConverter)\n",
    "    df['f_year'] = pd.to_datetime(df['f_year'])\n",
    "    df['f_reg_dt'] = pd.to_datetime(df['f_reg_dt'])\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=[\"f_brand\"])\n",
    "    \n",
    "    y = df.pop('l_price')\n",
    "    X = df\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    for col in X:\n",
    "        X[col] = scaler.fit_transform(X[[col]])\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "# ../../../assets/csv/시세예측/raw/model2/ 경로에서 가장 최근의 파일을 불러옴\n",
    "df = pd.read_csv(sorted(glob.glob(\"../../../assets/csv/시세예측/raw/model5/*.csv\"))[-1], encoding='cp949')\n",
    "scaled_df = df.copy()\n",
    "X, y = scale(scaled_df)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization candiate 정의\n",
    "reg_candidate = [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "# space 정의, Hyperparameter의 이름을 key 값으로 입력(xgboost)\n",
    "space={\n",
    "    'max_depth': hps.quniform(\"max_depth\", 5, 20, 1), # 트리의 최대 깊이\n",
    "    'learning_rate': hps.quniform ('learning_rate', 0.01, 0.05, 0.005), # 학습률\n",
    "    'reg_alpha': hps.choice('reg_alpha', reg_candidate), # L1정규화 Lasso회귀분석\n",
    "    'reg_lambda': hps.choice('reg_lambda', reg_candidate), # L2정규화 Ridge회귀분석\n",
    "    'subsample': hps.quniform('subsample', 0.01, 1, 0.01), # 트리를 생성할 때 데이터를 샘플링하는 비율\n",
    "    'colsample_bytree': hps.quniform('colsample_bytree', 0.01, 1, 0.01), # 트리를 생성할 때 피처를 샘플링하는 비율\n",
    "    'colsample_bylevel': hps.quniform('colsample_bylevel', 0.01, 1, 0.01), # 트리의 레벨별로 피처를 샘플링하는 비율\n",
    "    'colsample_bynode': hps.quniform('colsample_bynode', 0.01, 1, 0.01), # 트리의 노드별로 피처를 샘플링하는 비율\n",
    "    'min_child_weight': hps.quniform('min_child_weight', 1, 100, 1), # 트리의 리프노드가 되기 위한 최소한의 샘플 데이터 수\n",
    "    'n_estimators': hps.quniform('n_estimators', 100, 10000, 100), # 트리의 개수\n",
    "    'gamma': hps.quniform('gamma', 0.01, 1, 0.01), # 트리의 리프노드를 추가적으로 나눌지를 결정하는 파라미터\n",
    "}\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators =int(space['n_estimators']), \n",
    "        max_depth = int(space['max_depth']), \n",
    "        learning_rate = space['learning_rate'],\n",
    "        reg_alpha = space['reg_alpha'], # L1정규화 Lasso회귀분석\n",
    "        reg_lambda = space['reg_lambda'], # L2정규화 Ridge회귀분석\n",
    "        subsample = space['subsample'], # 각 트리마다의 관측 데이터 샘플링 비율\n",
    "        colsample_bytree = space['colsample_bytree'], # 각 트리마다의 feature 샘플링 비율\n",
    "        colsample_bylevel = space['colsample_bylevel'], # 각 트리 depth 마다 사용할 feature 비율\n",
    "        colsample_bynode = space['colsample_bynode'], # 각 트리 node 마다 사용할 feature 비율\n",
    "        min_child_weight = int(space['min_child_weight']), # child의 관측에서 요구되는 최소 가중치의 합(overfitting 조정 parameter)\n",
    "        gamma = space['gamma'], # 트리의 리프노드를 추가적으로 나눌지를 결정하는 파라미터\n",
    "        random_state=500, \n",
    "    )\n",
    "    \n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=evaluation, \n",
    "        eval_metric=\"rmse\",\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=0,\n",
    "    )\n",
    "    pred = model.predict(X_test)\n",
    "    rmse= cm.RMSE(y_test, pred)\n",
    "    # 평가 방식 선정\n",
    "    \n",
    "    return {'loss':rmse, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials 객체 선언합니다.\n",
    "trials = Trials()\n",
    "\n",
    "# best에 최적의 하이퍼 파라미터를 return 받습니다.\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials\n",
    "        )\n",
    "\n",
    "# 최적화된 결과를 int로 변환해야하는 파라미터는 타입 변환을 수행합니다.\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_weight'] = int(best['min_child_weight'])\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['reg_alpha'] = reg_candidate[int(best['reg_alpha'])]\n",
    "best['reg_lambda'] = reg_candidate[int(best['reg_lambda'])]\n",
    "best['random_state'] = 500\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation, Get Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "def kfold_xgb(xgb: XGBRegressor, X, y, n_splits=5, random_state=500):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    result = []\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        d = {}\n",
    "        loss = {\n",
    "            'MAE': \"\",\n",
    "            'RMSE': \"\",\n",
    "            'RMSLE': \"\",\n",
    "            'MAPE': \"\",\n",
    "            'R2': \"\",\n",
    "        }\n",
    "        print(f'Fold {i+1}: ')\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        now = time.time()\n",
    "        xgb.fit(X_train, y_train)\n",
    "        print(f'학습 시간: {time.time()-now:.2f}초')\n",
    "        now = time.time()\n",
    "        pred = xgb.predict(X_test)\n",
    "        TT_Sec = time.time()-now\n",
    "        print(f'예측 시간: {TT_Sec:.2f}초')\n",
    "        print('--------------------------------------')\n",
    "        loss['MAE'], loss['RMSE'], loss['RMSLE'], loss['MAPE'], loss['R2'], loss['TT(Sec)'] = cm.MAE(y_test, pred), cm.RMSE(y_test, pred), cm.RMSLE(y_test, pred), cm.MAPE(y_test, pred), cm.R2(y_test, pred), TT_Sec\n",
    "        result.append({\"model\": xgb, \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test, \"pred\": pred, \"loss\": loss})\n",
    "        \n",
    "    return result\n",
    "\n",
    "xgb = XGBRegressor(**best)\n",
    "result = kfold_xgb(xgb, X, y, n_splits=10, random_state=500)\n",
    "best_result = result[np.argmin([r['loss']['RMSLE'] for r in result])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([r['loss'] for r in result], index=[f'Fold {i+1}' for i in range(len(result))])\n",
    "\n",
    "print(f'Best: Fold {np.argmin([r[\"loss\"][\"RMSLE\"] for r in result])+1}')\n",
    "pred_df = pd.DataFrame({\n",
    "    '실제값': best_result['y_test'],\n",
    "    '예측값': best_result['pred'],\n",
    "})\n",
    "pred_df['오차값'] = (pred_df['예측값'] - pred_df['실제값'])\n",
    "pred_df['절대 오차값'] = (pred_df['예측값'] - pred_df['실제값']).abs()\n",
    "pred_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def show_plot():\n",
    "    dfs = {f\"Fold {i+1}\": pd.DataFrame({\n",
    "        '실제값': r['y_test'],\n",
    "        '예측값': r['pred'],\n",
    "        '오차값': (r['pred'] - r['y_test']),\n",
    "    }) for i, r in enumerate(result)}\n",
    "\n",
    "    y_len = len(result)\n",
    "    figure, axis = plt.subplots(y_len, 2, figsize=(20, 10*y_len))\n",
    "\n",
    "    best_fold = f'Fold {np.argmin([r[\"loss\"][\"RMSLE\"] for r in result])+1}'\n",
    "    for i, (key, df) in enumerate(dfs.items()):\n",
    "        # grid true\n",
    "        axis[i][0].grid(True)\n",
    "        x_line = np.arange(0, df[['실제값', '예측값']].max().max())\n",
    "        y_line = x_line + 0\n",
    "        axis[i][0].axis([df['실제값'].min(), df['실제값'].max(), df['예측값'].min(), df['예측값'].max()])\n",
    "        axis[i][0].scatter(df['실제값'], df['예측값'], alpha=.5, s=10)\n",
    "        axis[i][0].plot(x_line, y_line, color='red')  # draw line\n",
    "        axis[i][0].set_xlabel(df['실제값'].name)\n",
    "        axis[i][0].set_ylabel(df['예측값'].name)\n",
    "        if key == best_fold:\n",
    "            axis[i][0].set_title(key + ' (Best)')\n",
    "        else:\n",
    "            axis[i][0].set_title(key)\n",
    "        \n",
    "        # grid true\n",
    "        axis[i][1].grid(True)\n",
    "        axis[i][1].axis([df['실제값'].min(), df['실제값'].max(), df['오차값'].min(), df['오차값'].max()])\n",
    "        axis[i][1].scatter(df['실제값'], df['오차값'], alpha=.5, s=10)\n",
    "        axis[i][1].plot([df['실제값'].min(), df['실제값'].max()], [0, 0], color='red')\n",
    "        axis[i][1].set_xlabel(df['실제값'].name)\n",
    "        axis[i][1].set_ylabel(df['오차값'].name)\n",
    "        if key == best_fold:\n",
    "            axis[i][1].set_title(key + ' (Best)')\n",
    "        else:\n",
    "            axis[i][1].set_title(key)\n",
    "        # linear regression for 오차값\n",
    "        x_r = df['실제값'].values.reshape(-1, 1)\n",
    "        y_r = df['오차값'].values.reshape(-1, 1)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x_r, y_r)\n",
    "        axis[i][1].plot(x_r, lr.predict(x_r), color='green')\n",
    "        \n",
    "    plt.show();\n",
    "    \n",
    "show_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dt = datetime.now()\n",
    "\n",
    "model_path = \"../../../assets/csv/시세예측/model/model5\"\n",
    "train_path = \"../../../assets/csv/시세예측/train/model5\"\n",
    "test_path = \"../../../assets/csv/시세예측/test/model5\"\n",
    "cm.create_folder(model_path)\n",
    "cm.create_folder(train_path)\n",
    "cm.create_folder(test_path)\n",
    "\n",
    "# save xgBoost Model\n",
    "best_result['model'].save_model(f\"{model_path}/xg.{save_dt.strftime('%Y%m%d%H%I%S')}.json\")\n",
    "best_result['model'].save_model(f\"{model_path}/xg.{save_dt.strftime('%Y%m%d%H%I%S')}.model\")\n",
    "\n",
    "# save minMaxScaler Model\n",
    "mm_model = df.loc[best_result['X_train'].index][['f_mileage', 'f_year']].reset_index(drop=True)\n",
    "transformed_datetime = cm.transform_date(mm_model['f_year'].values.reshape(-1, 1))\n",
    "mm_model = pd.concat([mm_model, pd.DataFrame(transformed_datetime, columns=['transformed_datetime'])], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "mm_fit = scaler.fit(mm_model.drop(columns=['f_year']))\n",
    "\n",
    "with open(f\"{model_path}/mm.{save_dt.strftime('%Y%m%d%H%I%S')}.model\", 'wb') as f:\n",
    "    pickle.dump(mm_fit, f)\n",
    "    \n",
    "# save test, train set\n",
    "best_result['X_train'].to_csv(f\"{train_path}/X_train.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['X_test'].to_csv(f\"{test_path}/X_test.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['y_train'].to_csv(f\"{train_path}/y_train.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['y_test'].to_csv(f\"{test_path}/y_test.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4072f32cd894d8a478b19fcca03df2d0ab244b2d541bc7c55c292e4acce29c8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
