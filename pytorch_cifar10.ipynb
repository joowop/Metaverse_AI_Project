{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CIFAR10(\n",
    "    root = './',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root = './',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp in range(9):\n",
    "    plt.subplot(3,3,temp+1)\n",
    "    plt.imshow(train_data.data[temp])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00ba1d",
   "metadata": {},
   "source": [
    "# 데이터 증강\n",
    "- 회전\n",
    "- 사이즈 변형\n",
    "- 좌우, 상하 반전\n",
    "- 이동\n",
    "- crop (전체 이미지에서 잘라쓰기)\n",
    "\n",
    "#### 색깔의 영향을 받지 않기 위해 정규화 작업을 해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0335d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomCrop, Normalize\n",
    "import torchvision.transforms as T\n",
    "\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        T.ToPILImage(),\n",
    "        # 랜덤으로 이미지를 자르고 패딩을 4로 처리\n",
    "        RandomCrop((32,32), padding = 4),\n",
    "        # 0.5의 확률로 y축을 기준으로 반전 시킨다.\n",
    "        RandomHorizontalFlip(p = 0.5),\n",
    "        \n",
    "        T.ToTensor(),\n",
    "        # R,G,B의 평균, 표준편차\n",
    "        Normalize(mean = (0.4733, 0.4643, 0.4465), std = (0.251, 0.253, 0.261)),\n",
    "        T.ToPILImage()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = CIFAR10(\n",
    "    root = './',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root = './',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "for temp in range(9):\n",
    "    plt.subplot(3,3,temp+1)\n",
    "    plt.imshow(test_transforms(train_data.data[temp]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9cbed",
   "metadata": {},
   "source": [
    "## 이미지 R,G,B 평균 표준편차 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a677d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for temp in train_data:\n",
    "    imgs.append(temp[0])\n",
    "\n",
    "# 이미지들을 하나로 합쳐서 통합을 시킨다.\n",
    "imgs = torch.stack(imgs, dim = 0).numpy()\n",
    "\n",
    "# 0번째는 R 1은 G 2는 B\n",
    "mean_r = imgs[:,0:,:].mean()\n",
    "mean_g = imgs[:,1:,:].mean()\n",
    "mean_b = imgs[:,2:,:].mean()\n",
    "print(mean_r, mean_g, mean_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_r = imgs[:,0:,:].std()\n",
    "std_g = imgs[:,1:,:].std()\n",
    "std_b = imgs[:,2:,:].std()\n",
    "print(std_r, std_g, std_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29084477",
   "metadata": {},
   "source": [
    "# 시드 값 고정\n",
    "- 4가지 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5399276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(100)\n",
    "torch.cuda.manual_seed(100)\n",
    "torch.cuda.manual_seed_all(100)\n",
    "np.random.seed(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667dee1b",
   "metadata": {},
   "source": [
    "# VGG 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ca991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6dfa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,hidden_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, out_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.block1 = BasicBlock(in_channels=3,out_channels=32,hidden_dim=16)\n",
    "        self.block2 = BasicBlock(in_channels=32,out_channels=128,hidden_dim=64)\n",
    "        self.block3 = BasicBlock(in_channels=128,out_channels=256,hidden_dim=128)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3157b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BasicBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, hidden_dim):\n",
    "#         super(BasicBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, hidden_dim, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(hidden_dim, out_channels, kernel_size = 3, padding = 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.pool(x)\n",
    "        \n",
    "#         return x\n",
    "    \n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         # 스트라이드 출력 크기 계산 알아야함. 입 출력 데이터가 어케 변하는지\n",
    "#         ## (w + 2p - fw)/s +1 계산으로 인해 32이지만 maxpool로 인해 절반 나가리\n",
    "#         ### 32*32\n",
    "#         self.block1 = BasicBlock(in_channels=3,out_channels=32,hidden_dim=16)\n",
    "#         ### 16*16\n",
    "#         self.block2 = BasicBlock(in_channels=32, out_channels=128, hidden_dim=64)\n",
    "#         ### 8*8의 \n",
    "#         self.block3 = BasicBlock(in_channels=128, out_channels=256, hidden_dim=128)\n",
    "#         ### 최종적으로 4*4 256이 나오게 된다.\n",
    "        \n",
    "#         # 4*4*256\n",
    "#         self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
    "#         self.fc2 = nn.Linear(in_features=2048, out_features=256)\n",
    "#         self.fc3 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.block1(x)\n",
    "#         x = self.block2(x)\n",
    "#         x = self.block3(x)\n",
    "#         x = torch.flatten(x, start_dim = 1)\n",
    "        \n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc3(x)\n",
    "        \n",
    "#         return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6794aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.adam import Adam\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import RandomCrop, RandomHorizontalFlip,Normalize\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709d5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    RandomCrop((32,32),padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    Normalize(mean=(0.4914,0.4822,0.4465),std=(0.247,0.243,0.261))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2363099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (block1): BasicBlock(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block2): BasicBlock(\n",
       "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block3): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = CIFAR10(root='./',train=True,download=True,transform=transforms)\n",
    "test_data = CIFAR10(root='./',train=False,download=True,transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CNN(10)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd11227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SummaryWriter 인스턴스 생성\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b9f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 loss:0.8389108180999756\n",
      "epoch : 2 loss:1.526585340499878\n",
      "epoch : 3 loss:0.8053567409515381\n",
      "epoch : 4 loss:1.1447548866271973\n",
      "epoch : 5 loss:0.9441565871238708\n",
      "epoch : 6 loss:0.5827739238739014\n",
      "epoch : 7 loss:0.8425121307373047\n",
      "epoch : 8 loss:0.970990002155304\n",
      "epoch : 9 loss:0.5536876320838928\n",
      "epoch : 10 loss:0.4515862464904785\n",
      "epoch : 11 loss:0.438700795173645\n",
      "epoch : 12 loss:0.3833353519439697\n",
      "epoch : 13 loss:0.4236484169960022\n",
      "epoch : 14 loss:0.5880935788154602\n",
      "epoch : 15 loss:0.7043348550796509\n",
      "epoch : 16 loss:0.2540919780731201\n",
      "epoch : 17 loss:0.9258472919464111\n",
      "epoch : 18 loss:0.3941402733325958\n",
      "epoch : 19 loss:1.0268940925598145\n",
      "epoch : 20 loss:0.20321154594421387\n",
      "epoch : 21 loss:0.7881424427032471\n",
      "epoch : 22 loss:0.31635287404060364\n",
      "epoch : 23 loss:0.27432072162628174\n",
      "epoch : 24 loss:0.5567041039466858\n",
      "epoch : 25 loss:0.23771774768829346\n",
      "epoch : 26 loss:0.10682253539562225\n",
      "epoch : 27 loss:0.8278865814208984\n",
      "epoch : 28 loss:0.3112070560455322\n",
      "epoch : 29 loss:0.731756865978241\n",
      "epoch : 30 loss:0.3866055905818939\n",
      "epoch : 31 loss:0.4377979636192322\n",
      "epoch : 32 loss:0.2043582797050476\n",
      "epoch : 33 loss:0.21051903069019318\n",
      "epoch : 34 loss:0.17987577617168427\n",
      "epoch : 35 loss:0.40211746096611023\n",
      "epoch : 36 loss:0.3368523418903351\n",
      "epoch : 37 loss:0.1882951408624649\n",
      "epoch : 38 loss:0.44770246744155884\n",
      "epoch : 39 loss:0.4455382823944092\n",
      "epoch : 40 loss:0.448553204536438\n",
      "epoch : 41 loss:0.46501514315605164\n",
      "epoch : 42 loss:0.7361708879470825\n",
      "epoch : 43 loss:0.3603529930114746\n",
      "epoch : 44 loss:0.47134044766426086\n",
      "epoch : 45 loss:0.6345698237419128\n",
      "epoch : 46 loss:0.3471756875514984\n",
      "epoch : 47 loss:0.4260406494140625\n",
      "epoch : 48 loss:0.2978964149951935\n",
      "epoch : 49 loss:0.167548269033432\n",
      "epoch : 50 loss:0.4881432056427002\n",
      "epoch : 51 loss:0.40020686388015747\n",
      "epoch : 52 loss:0.3417864739894867\n",
      "epoch : 53 loss:1.254749059677124\n",
      "epoch : 54 loss:0.2190050333738327\n",
      "epoch : 55 loss:0.6196568012237549\n",
      "epoch : 56 loss:0.06563772261142731\n",
      "epoch : 57 loss:0.34726953506469727\n",
      "epoch : 58 loss:0.5879135727882385\n",
      "epoch : 59 loss:0.16878317296504974\n",
      "epoch : 60 loss:0.1789640486240387\n",
      "epoch : 61 loss:0.25599610805511475\n",
      "epoch : 62 loss:0.2756064534187317\n",
      "epoch : 63 loss:0.1657654494047165\n",
      "epoch : 64 loss:0.22794701159000397\n",
      "epoch : 65 loss:0.8075079917907715\n",
      "epoch : 66 loss:0.21206705272197723\n",
      "epoch : 67 loss:0.2682035565376282\n",
      "epoch : 68 loss:0.831723153591156\n",
      "epoch : 69 loss:0.14196166396141052\n",
      "epoch : 70 loss:0.06417401134967804\n",
      "epoch : 71 loss:0.8444327712059021\n",
      "epoch : 72 loss:0.38236209750175476\n",
      "epoch : 73 loss:0.16448557376861572\n",
      "epoch : 74 loss:0.12369317561388016\n",
      "epoch : 75 loss:0.040387868881225586\n",
      "epoch : 76 loss:0.21191129088401794\n",
      "epoch : 77 loss:0.2134036421775818\n",
      "epoch : 78 loss:0.7949742674827576\n",
      "epoch : 79 loss:0.9872609376907349\n",
      "epoch : 80 loss:0.44565731287002563\n",
      "epoch : 81 loss:1.1181275844573975\n",
      "epoch : 82 loss:0.7445918917655945\n",
      "epoch : 83 loss:0.307697057723999\n",
      "epoch : 84 loss:0.30451875925064087\n",
      "epoch : 85 loss:0.16786468029022217\n",
      "epoch : 86 loss:0.38766220211982727\n",
      "epoch : 87 loss:0.1804634928703308\n",
      "epoch : 88 loss:0.3048887252807617\n",
      "epoch : 89 loss:0.44376468658447266\n",
      "epoch : 90 loss:0.30101171135902405\n",
      "epoch : 91 loss:0.5752440094947815\n",
      "epoch : 92 loss:0.3119230270385742\n",
      "epoch : 93 loss:0.2096204161643982\n",
      "epoch : 94 loss:0.6121586561203003\n",
      "epoch : 95 loss:0.05029764771461487\n",
      "epoch : 96 loss:0.6754277348518372\n",
      "epoch : 97 loss:0.6820313930511475\n",
      "epoch : 98 loss:0.029804084450006485\n",
      "epoch : 99 loss:0.6058821082115173\n",
      "epoch : 100 loss:0.25446617603302\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "optim = Adam(model.parameters(),lr=lr)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for data,label in train_loader:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        preds = model(data.to(device))\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(preds,label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    print(f'epoch : {epoch+1} loss:{loss.item()}')\n",
    "    writer.add_scalar(\"Loss/train\", loss.item(), epoch+1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01d692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cifar-cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc8d425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_corr =  0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data,label in test_loader:\n",
    "        pred = model(data.to(device))\n",
    "        preds = pred.data.max(1)[1]\n",
    "        corr = preds.eq(label.to(device).data).sum().item()\n",
    "        num_corr += corr\n",
    "num_corr/len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29bb223d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8b108c44df7439c9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8b108c44df7439c9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=/tmp/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf79541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fbebc28b5161e86\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fbebc28b5161e86\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6060;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 쓰기 종료\n",
    "writer.close()\n",
    "\n",
    "#코랩 안에서 띄우기위함\n",
    "%load_ext tensorboard\n",
    "#경로로 불러오기\n",
    "%tensorboard --logdir=runs --port 6060\n",
    "# %tensorboard --logdir [경로] --port 6060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc597735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307c48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
