{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model4:\n",
    "### 중형트럭: 5톤 중심의 화물운송 핵심 차량 \n",
    "### 준대형트럭: 중형의 경제성 + 대형급 적재능력\n",
    "- 4.5톤 Base ( t >= 4.5 & t < 9.5) -> 준대형은 중형트럭 엔진과 섀시를 공유하는 차량\n",
    "- 중형트럭: 중형트럭은 적재중량 4.5톤 ~ 8.5톤까지의 트럭을 말한다.<br>\n",
    "  이 차급부터 구동축은 4×2(4개 바퀴 축 중 구동축 2개)와 가변축을 탑재한 6×2 차량으로 나뉜다.<br>\n",
    "  중형트럭의 연간 신규등록대수는 1만 1,000 ~ 1만 3,000대 수준으로 소형트럭을 제외하면, 가장 큰 시장을 갖고 있다. <br>\n",
    "  중형트럭의 구동축은 4×2를 기본으로 하며, 여기에 가변축(6×2)을 하나 더 장착하게 되면, 도로법 기준에 따라 축당 10톤씩 중량물이 허용돼, 차주들에게 인기가 좋다. <br>\n",
    "  대표적인 차종으로 현대차 메가트럭, 타타대우 프리마·노부스(280마력), 볼보트럭 FL, 메르세데스-벤츠 아테고 등이 있다. <br>\n",
    "- 준대형트럭: 업종개편 이후 4.5톤에 제한됐던 영업용(개인) 번호판이 최대 16톤까지 허용됨에 따라 새롭게 부각된 차급이 바로 준대형트럭이다.<br>\n",
    "  준대형트럭은 8톤부터 16톤까지 중형트럭과 대형트럭 간 교차점이 발생하는 차급으로 지난해 약 1,300여 대가 신규등록됐다.<br>\n",
    "  이 차급의 특징으로 중형트럭 엔진과 섀시를 공유하며 가변축 장착을 위해 긴 축거(휠베이스)를 가졌다. <br>\n",
    "  이에 따라 기본축은 5톤급의 4×2이지만, 가변축(6×2)을 통해 8톤 이상으로 증톤하거나 8 ~ 9톤급의 6×4 모델로 출시 후 가변축을 장착해 14톤, 16톤 등으로 증톤이 가능하다.<br>\n",
    "  덧붙여 이들 차량의 엔진은 중형트럭에 장착되는 6 ~ 7리터(ℓ)급 엔진이 탑재됐으나, 중형트럭과 차급 구분을 위해 캡(Cabin) 크기를 소폭 키웠다.<br>\n",
    "  준대형트럭을 대표하는 모델로는 현대차 파비스·뉴파워트럭, 타타대우 프리마(고하중), 볼보트럭 FE, 메르세데스-벤츠 아록스(299마력), 만트럭 T GM(320마력) 모델 등이 속한다.\n",
    "- 9.5톤 이상\n",
    "- 적재중량 9.5톤 이상 대형차량의 플랫폼으로 설계된 차량에 한정된다. <br>\n",
    "  이 차급부터 본격적으로 9리터급 이상의 대배기량 엔진이 장착된다.<br>\n",
    "  대형트럭은 중형트럭과 섀시를 공유하지 않고, 저상카고인 9.5톤부터, 14톤, 16톤, 18톤, 22톤, 25톤 등의 독자적인 플랫폼을 갖췄다. <br>\n",
    "  이들 수요는 한해 약 5,000 ~ 5,500여 대 수준이다. <br>\n",
    "  적재중량에 맞춰 구동축은 9.5톤부터 18톤까지는 6×4를 기본으로 하며, 19 ~ 23톤급은 8×4, 24톤 이상 트럭은 10×4 구동축을 갖는다. <br>\n",
    "  대형트럭의 캡은 저상캡을 비롯해, 표준캡, 슬리퍼캡 등 중형과 준대형트럭에 비해 월등히 큰 공간을 자랑한다. <br>\n",
    "  대형트럭에 속하는 모델로는 현대차 엑시언트, 볼보트럭 FH·FM, 다임러 아록스, 스카니아 R·G 시리즈 등이 있다.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp as hps, tpe\n",
    "import pickle\n",
    "# modules 폴더를 path에 추가(본인 컴퓨터에 맞게 수정)\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "module_path = root_path + '\\\\modules'\n",
    "sys.path.insert(1, module_path)\n",
    "from common import common as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import json\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "font_path = \"../../../assets/fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "# 하나의 cell에서 multiple output 출력\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# float > 소수점 두자리까지만\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "# 컬럼 길이 제한 없음\n",
    "try:\n",
    "    pd.set_option('max_columns', None)\n",
    "    pd.set_option('max_rows', 500)\n",
    "except:\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = 500\n",
    "\n",
    "# 아래 코드에서 100%를 본인이 원하는 비율로 조정하여, 가로로 넓게 코드작성이 가능하고, 데이터를 보는데 쾌적한 환경을 조성할 수 있음\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call 아이트럭 raw data\n",
    "from calldb import db_helper\n",
    "itruck = db_helper(server=\"REL\").table(\"SELECT * FROM TB_MYCAR;\")\n",
    "\n",
    "max_workers = min(32, os.cpu_count() + 4)\n",
    "# call 특장차8949 raw data\n",
    "tjc = cm.read_all_csv(path=root_path+\"/assets/csv/특장차8949/\", workers=max_workers)\n",
    "\n",
    "# call 카매니저 raw data\n",
    "cmg = cm.read_all_json(path=root_path+\"/assets/json/카매니저/metaData/\", workers=max_workers)\n",
    "\n",
    "print(f\"itruck shape: {itruck.shape}\\ntjc shape: {tjc.shape}\\ncmg shape: {cmg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df):\n",
    "    df = df.drop(columns=['id', 'f_ton'])\n",
    "    \n",
    "    df['f_brand'] = df['f_brand'].replace({\n",
    "        '현대': 'hyundai',\n",
    "        '타타대우_프리마': 'daewoo_prima',\n",
    "        '타타대우_노부스': 'daewoo_novus',\n",
    "        '유럽': 'europe',\n",
    "    })\n",
    "    \n",
    "    df['f_year'] = pd.to_datetime(df['f_year'])\n",
    "    df['f_reg_dt'] = pd.to_datetime(df['f_reg_dt'])\n",
    "    df['f_mileage'] = df['f_mileage'].astype(int)\n",
    "    df['f_trm'] = df['f_trm'].astype(int)\n",
    "    df['f_loader_len'] = df['f_loader_len'].astype(int)\n",
    "    df['f_hp'] = df['f_hp'].astype(int)\n",
    "    df['l_price'] = df['l_price'].astype(int)\n",
    "    \n",
    "    df['f_category'] = df['f_category'].replace({\n",
    "        '카고': 'cargo',\n",
    "        '내장탑': 'top',\n",
    "        '냉동냉장차': 'refrige',\n",
    "        '윙바디': 'wing',\n",
    "    })\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=[\"f_brand\", \"f_category\"])\n",
    "    \n",
    "    y = df.pop('l_price')\n",
    "    X = df\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    for col in X:\n",
    "        X[col] = scaler.fit_transform(X[[col]])\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "# ../../../assets/csv/시세예측/raw/model2/ 경로에서 가장 최근의 파일을 불러옴\n",
    "df = pd.read_csv(sorted(glob.glob(\"../../../assets/csv/시세예측/raw/model4/*.csv\"))[-1], encoding='cp949')\n",
    "scaled_df = df.copy()\n",
    "X, y = scale(scaled_df)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization candiate 정의\n",
    "reg_candidate = [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "# space 정의, Hyperparameter의 이름을 key 값으로 입력(xgboost)\n",
    "space={\n",
    "    'max_depth': hps.quniform(\"max_depth\", 5, 20, 1), # 트리의 최대 깊이\n",
    "    'learning_rate': hps.quniform ('learning_rate', 0.01, 0.05, 0.005), # 학습률\n",
    "    'reg_alpha': hps.choice('reg_alpha', reg_candidate), # L1정규화 Lasso회귀분석\n",
    "    'reg_lambda': hps.choice('reg_lambda', reg_candidate), # L2정규화 Ridge회귀분석\n",
    "    'subsample': hps.quniform('subsample', 0.01, 1, 0.01), # 트리를 생성할 때 데이터를 샘플링하는 비율\n",
    "    'colsample_bytree': hps.quniform('colsample_bytree', 0.01, 1, 0.01), # 트리를 생성할 때 피처를 샘플링하는 비율\n",
    "    'colsample_bylevel': hps.quniform('colsample_bylevel', 0.01, 1, 0.01), # 트리의 레벨별로 피처를 샘플링하는 비율\n",
    "    'colsample_bynode': hps.quniform('colsample_bynode', 0.01, 1, 0.01), # 트리의 노드별로 피처를 샘플링하는 비율\n",
    "    'min_child_weight': hps.quniform('min_child_weight', 1, 100, 1), # 트리의 리프노드가 되기 위한 최소한의 샘플 데이터 수\n",
    "    'n_estimators': hps.quniform('n_estimators', 100, 10000, 100), # 트리의 개수\n",
    "    'gamma': hps.quniform('gamma', 0.01, 1, 0.01), # 트리의 리프노드를 추가적으로 나눌지를 결정하는 파라미터\n",
    "}\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators =int(space['n_estimators']), \n",
    "        max_depth = int(space['max_depth']), \n",
    "        learning_rate = space['learning_rate'],\n",
    "        reg_alpha = space['reg_alpha'], # L1정규화 Lasso회귀분석\n",
    "        reg_lambda = space['reg_lambda'], # L2정규화 Ridge회귀분석\n",
    "        subsample = space['subsample'], # 각 트리마다의 관측 데이터 샘플링 비율\n",
    "        colsample_bytree = space['colsample_bytree'], # 각 트리마다의 feature 샘플링 비율\n",
    "        colsample_bylevel = space['colsample_bylevel'], # 각 트리 depth 마다 사용할 feature 비율\n",
    "        colsample_bynode = space['colsample_bynode'], # 각 트리 node 마다 사용할 feature 비율\n",
    "        min_child_weight = int(space['min_child_weight']), # child의 관측에서 요구되는 최소 가중치의 합(overfitting 조정 parameter)\n",
    "        gamma = space['gamma'], # 트리의 리프노드를 추가적으로 나눌지를 결정하는 파라미터\n",
    "        random_state=400, \n",
    "    )\n",
    "    \n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=evaluation, \n",
    "        eval_metric=\"rmse\",\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=0,\n",
    "    )\n",
    "    pred = model.predict(X_test)\n",
    "    rmse= cm.RMSE(y_test, pred)\n",
    "    # 평가 방식 선정\n",
    "    \n",
    "    return {'loss':rmse, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials 객체 선언합니다.\n",
    "trials = Trials()\n",
    "\n",
    "# best에 최적의 하이퍼 파라미터를 return 받습니다.\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials\n",
    "        )\n",
    "\n",
    "# 최적화된 결과를 int로 변환해야하는 파라미터는 타입 변환을 수행합니다.\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_weight'] = int(best['min_child_weight'])\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['reg_alpha'] = reg_candidate[int(best['reg_alpha'])]\n",
    "best['reg_lambda'] = reg_candidate[int(best['reg_lambda'])]\n",
    "best['random_state'] = 400\n",
    "print(best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation, Get Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "def kfold_xgb(xgb: XGBRegressor, X, y, n_splits=5, random_state=400):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    result = []\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        d = {}\n",
    "        loss = {\n",
    "            'MAE': \"\",\n",
    "            'RMSE': \"\",\n",
    "            'RMSLE': \"\",\n",
    "            'MAPE': \"\",\n",
    "            'R2': \"\",\n",
    "        }\n",
    "        print(f'Fold {i+1}: ')\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        now = time.time()\n",
    "        xgb.fit(X_train, y_train)\n",
    "        print(f'학습 시간: {time.time()-now:.2f}초')\n",
    "        now = time.time()\n",
    "        pred = xgb.predict(X_test)\n",
    "        TT_Sec = time.time()-now\n",
    "        print(f'예측 시간: {TT_Sec:.2f}초')\n",
    "        print('--------------------------------------')\n",
    "        loss['MAE'], loss['RMSE'], loss['RMSLE'], loss['MAPE'], loss['R2'], loss['TT(Sec)'] = cm.MAE(y_test, pred), cm.RMSE(y_test, pred), cm.RMSLE(y_test, pred), cm.MAPE(y_test, pred), cm.R2(y_test, pred), TT_Sec\n",
    "        result.append({\"model\": xgb, \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test, \"pred\": pred, \"loss\": loss})\n",
    "        \n",
    "    return result\n",
    "\n",
    "xgb = XGBRegressor(**best)\n",
    "result = kfold_xgb(xgb, X, y, n_splits=10, random_state=400)\n",
    "best_result = result[np.argmin([r['loss']['RMSLE'] for r in result])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([r['loss'] for r in result], index=[f'Fold {i+1}' for i in range(len(result))])\n",
    "\n",
    "print(f'Best: Fold {np.argmin([r[\"loss\"][\"RMSLE\"] for r in result])+1}')\n",
    "pred_df = pd.DataFrame({\n",
    "    '실제값': best_result['y_test'],\n",
    "    '예측값': best_result['pred'],\n",
    "})\n",
    "pred_df['오차값'] = (pred_df['예측값'] - pred_df['실제값'])\n",
    "pred_df['절대 오차값'] = (pred_df['예측값'] - pred_df['실제값']).abs()\n",
    "pred_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def show_plot():\n",
    "    dfs = {f\"Fold {i+1}\": pd.DataFrame({\n",
    "        '실제값': r['y_test'],\n",
    "        '예측값': r['pred'],\n",
    "        '오차값': (r['pred'] - r['y_test']),\n",
    "    }) for i, r in enumerate(result)}\n",
    "\n",
    "    y_len = len(result)\n",
    "    figure, axis = plt.subplots(y_len, 2, figsize=(20, 10*y_len))\n",
    "\n",
    "    best_fold = f'Fold {np.argmin([r[\"loss\"][\"RMSLE\"] for r in result])+1}'\n",
    "    for i, (key, df) in enumerate(dfs.items()):\n",
    "        # grid true\n",
    "        axis[i][0].grid(True)\n",
    "        x_line = np.arange(0, df[['실제값', '예측값']].max().max())\n",
    "        y_line = x_line + 0\n",
    "        axis[i][0].axis([df['실제값'].min(), df['실제값'].max(), df['예측값'].min(), df['예측값'].max()])\n",
    "        axis[i][0].scatter(df['실제값'], df['예측값'], alpha=.5, s=10)\n",
    "        axis[i][0].plot(x_line, y_line, color='red')  # draw line\n",
    "        axis[i][0].set_xlabel(df['실제값'].name)\n",
    "        axis[i][0].set_ylabel(df['예측값'].name)\n",
    "        if key == best_fold:\n",
    "            axis[i][0].set_title(key + ' (Best)')\n",
    "        else:\n",
    "            axis[i][0].set_title(key)\n",
    "        \n",
    "        # grid true\n",
    "        axis[i][1].grid(True)\n",
    "        axis[i][1].axis([df['실제값'].min(), df['실제값'].max(), df['오차값'].min(), df['오차값'].max()])\n",
    "        axis[i][1].scatter(df['실제값'], df['오차값'], alpha=.5, s=10)\n",
    "        axis[i][1].plot([df['실제값'].min(), df['실제값'].max()], [0, 0], color='red')\n",
    "        axis[i][1].set_xlabel(df['실제값'].name)\n",
    "        axis[i][1].set_ylabel(df['오차값'].name)\n",
    "        if key == best_fold:\n",
    "            axis[i][1].set_title(key + ' (Best)')\n",
    "        else:\n",
    "            axis[i][1].set_title(key)\n",
    "        # linear regression for 오차값\n",
    "        x_r = df['실제값'].values.reshape(-1, 1)\n",
    "        y_r = df['오차값'].values.reshape(-1, 1)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x_r, y_r)\n",
    "        axis[i][1].plot(x_r, lr.predict(x_r), color='green')\n",
    "        \n",
    "    plt.show();\n",
    "    \n",
    "show_plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dt = datetime.now()\n",
    "\n",
    "model_path = \"../../../assets/csv/시세예측/model/model4\"\n",
    "train_path = \"../../../assets/csv/시세예측/train/model4\"\n",
    "test_path = \"../../../assets/csv/시세예측/test/model4\"\n",
    "cm.create_folder(model_path)\n",
    "cm.create_folder(train_path)\n",
    "cm.create_folder(test_path)\n",
    "\n",
    "# save xgBoost Model\n",
    "best_result['model'].save_model(f\"{model_path}/xg.{save_dt.strftime('%Y%m%d%H%I%S')}.json\")\n",
    "best_result['model'].save_model(f\"{model_path}/xg.{save_dt.strftime('%Y%m%d%H%I%S')}.model\")\n",
    "\n",
    "# save minMaxScaler Model\n",
    "mm_model = df.loc[best_result['X_train'].index][['f_mileage', 'f_year']].reset_index(drop=True)\n",
    "transformed_datetime = cm.transform_date(mm_model['f_year'].values.reshape(-1, 1))\n",
    "mm_model = pd.concat([mm_model, pd.DataFrame(transformed_datetime, columns=['transformed_datetime'])], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "mm_fit = scaler.fit(mm_model.drop(columns=['f_year']))\n",
    "\n",
    "with open(f\"{model_path}/mm.{save_dt.strftime('%Y%m%d%H%I%S')}.model\", 'wb') as f:\n",
    "    pickle.dump(mm_fit, f)\n",
    "    \n",
    "# save test, train set\n",
    "best_result['X_train'].to_csv(f\"{train_path}/X_train.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['X_test'].to_csv(f\"{test_path}/X_test.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['y_train'].to_csv(f\"{train_path}/y_train.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')\n",
    "best_result['y_test'].to_csv(f\"{test_path}/y_test.{save_dt.strftime('%Y%m%d%H%I%S')}.csv\", index=False, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4072f32cd894d8a478b19fcca03df2d0ab244b2d541bc7c55c292e4acce29c8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
